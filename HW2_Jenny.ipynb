{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict if a document addresses the topic \"EARN\" or not\n",
    "‘create_training_data’ and ‘create_testing_data’ modules in ‘cls’ \n",
    "‘train_decision_tree’ module. \n",
    "‘print_decision_tree’ module. \n",
    "‘evaluate_classifier’ module. \n",
    "‘compute_evaluation_metrics’ module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextMining_cls_wk_2 import *\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model, pipeline, feature_extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5 points): rule based classifier to predict the topic \"EARN\" or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Creating training data\n",
      "TMPY> Tokenizing documents\n",
      "TMPY> Removing stopwords\n",
      "TMPY> Stemming tokens\n",
      "TMPY> Generating dictionary\n",
      "TMPY> Vectorizing documents\n",
      "TMPY> Extracting bow features\n"
     ]
    }
   ],
   "source": [
    "traindata, vocab = create_training_data('earn', 30, 'tmsk_trn.properties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Creating testing data\n",
      "TMPY> Tokenizing documents\n",
      "TMPY> Removing stopwords\n",
      "TMPY> Stemming tokens\n",
      "TMPY> Vectorizing documents\n",
      "TMPY> Extracting bow features\n"
     ]
    }
   ],
   "source": [
    "testdata = create_testing_data('earn', vocab, 'tmsk_tst.properties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame(traindata[0])\n",
    "df1 = pd.DataFrame(traindata[1])\n",
    "df0 = pd.concat([df0, pd.DataFrame([0]*len(df0), columns=['earn'])], axis=1)\n",
    "df1 = pd.concat([df1, pd.DataFrame([1]*len(df1), columns=['earn'])], axis=1)\n",
    "train_df = pd.concat([df0, df1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Training decision tree\n"
     ]
    }
   ],
   "source": [
    "treeClassifier = train_decision_tree(train_df.drop(columns=['earn']), train_df['earn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Saving decision tree\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.datasets import load_iris\\nimport pydotplus\\niris = load_iris()\\nclf = tree.DecisionTreeClassifier()\\nclf = clf.fit(iris.data, iris.target)\\ndot_data = StringIO()\\ntree.export_graphviz(clf, out_file=dot_data)\\ngraph = pydotplus.graphviz.graph_from_dot_data(dot_data.getvalue())\\ngraph.write_png(\"output.png\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_decision_tree(treeClassifier, 'treefile')\n",
    "'''\n",
    "from sklearn.datasets import load_iris\n",
    "import pydotplus\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(clf, out_file=dot_data)\n",
    "graph = pydotplus.graphviz.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_png(\"output.png\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Evaluating classifier\n"
     ]
    }
   ],
   "source": [
    "df0_test = pd.DataFrame(testdata[0])\n",
    "df1_test = pd.DataFrame(testdata[1])\n",
    "df0_test = pd.concat([df0_test, pd.DataFrame([0]*len(df0_test), columns=['earn'])], axis=1)\n",
    "df1_test = pd.concat([df1_test, pd.DataFrame([1]*len(df1_test), columns=['earn'])], axis=1)\n",
    "test_df = pd.concat([df0_test, df1_test]).reset_index(drop=True)\n",
    "test_df.shape\n",
    "treePred = evaluate_classifier(treeClassifier, test_df.drop(columns=['earn']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Computing evaluation metrics\n",
      "Precision: [0.73724921 0.98758389 1.        ]\n",
      "Recall: [1.         0.96491803 0.        ]\n",
      "Accuracy: 0.9651921682378535\n"
     ]
    }
   ],
   "source": [
    "compute_evaluation_metrics(test_df['earn'], treePred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2 points): variants of decision-tree to induce different rule learning strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Evaluating classifier\n",
      "    depth  meanAccuracy    stdAcc  validAccuracy\n",
      "0       1      0.801178  0.214958       0.926275\n",
      "1       2      0.919371  0.023251       0.942229\n",
      "2       3      0.937238  0.018254       0.961325\n",
      "3       4      0.945096  0.016605       0.962292\n",
      "4       5      0.946499  0.018977       0.963500\n",
      "5       6      0.950148  0.018227       0.973894\n",
      "6       7      0.952393  0.020892       0.972444\n",
      "7       8      0.949961  0.022604       0.975828\n",
      "8       9      0.949680  0.024569       0.975344\n",
      "9      10      0.948652  0.025247       0.975103\n",
      "10     11      0.950148  0.024789       0.971235\n",
      "11     12      0.949868  0.027284       0.972202\n",
      "12     13      0.945848  0.033527       0.970752\n",
      "13     14      0.945754  0.032989       0.972444\n",
      "14     15      0.943696  0.035614       0.968576\n",
      "15     16      0.943322  0.036194       0.968576\n",
      "16     17      0.941920  0.037313       0.969785\n",
      "17     18      0.942948  0.034997       0.972927\n",
      "18     19      0.943042  0.037862       0.970752\n",
      "19     20      0.942388  0.038501       0.970752\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for max_depth in range(1,31):\n",
    "    treeClassifier = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    scores = cross_val_score(treeClassifier, train_df.drop(columns=['earn']), train_df['earn'], cv=5)\n",
    "    treeClassifier.fit(train_df.drop(columns=['earn']), train_df['earn'])\n",
    "    results.append({'depth': max_depth, \n",
    "                    'meanAccuracy': scores.mean(), 'stdAcc': scores.std(),\n",
    "                    'validAccuracy': accuracy_score(test_df['earn'], \n",
    "                                                    evaluate_classifier(treeClassifier, test_df.drop(columns=['earn'])))})\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Evaluating classifier\n",
      "TMPY> Computing evaluation metrics\n",
      "Precision: [0.73724921 0.98617056 1.        ]\n",
      "Recall: [1.         0.98196721 0.        ]\n",
      "Accuracy: 0.9765530577713318\n"
     ]
    }
   ],
   "source": [
    "#the best depth = 10, we use it to train\n",
    "treeClassifier = DecisionTreeClassifier(max_depth=10)\n",
    "bestTree = treeClassifier.fit(train_df.drop(columns=['earn']), train_df['earn'])\n",
    "compute_evaluation_metrics(test_df['earn'], evaluate_classifier(bestTree, test_df.drop(columns=['earn'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2 points): Verify Figure 3.17 and compute the class for doc with w1 and w2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   w1  w2  w3  w4  Class\n",
       "0   1   0   0   1      1\n",
       "1   0   0   0   1      0\n",
       "2   1   1   0   1      0\n",
       "3   1   0   1   1      1\n",
       "4   0   1   1   0      0\n",
       "5   1   0   0   0      0\n",
       "6   1   0   1   0      1\n",
       "7   0   1   0   0      1\n",
       "8   0   1   0   1      0\n",
       "9   1   1   1   0      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSample = pd.DataFrame([[1,0,0,1,1],[0,0,0,1,0],[1,1,0,1,0],[1,0,1,1,1],[0,1,1,0,0],[1,0,0,0,0],[1,0,1,0,1],[0,1,0,0,1],\n",
    "                          [0,1,0,1,0],[1,1,1,0,0]], columns=['w1','w2','w3','w4','Class'])\n",
    "wordSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Class=1  Class=0\n",
      "   pr(Class)    0.6    0.4\n",
      "pr(w1|Class)    0.75    0.5\n",
      "pr(w2|Class)    0.25    0.6666666666666666\n",
      "pr(w3|Class)    0.5    0.3333333333333333\n",
      "pr(w4|Class)    0.5    0.5\n",
      "Probability for class = 0 if a document has w1 and w2 =  0.5846153846153845\n",
      "Probability for class = 1 if a document has w1 and w2 =  0.41538461538461546\n"
     ]
    }
   ],
   "source": [
    "class0 = wordSample.Class.loc[lambda s: s == 0].index\n",
    "class1 = wordSample.Class.loc[lambda s: s == 1].index\n",
    "#Pr(Class = 1)\n",
    "p1 = len(class0)/len(wordSample)\n",
    "#Pr(Class = 0)\n",
    "p2 = len(class1)/len(wordSample)\n",
    "#Pr(w1=1|Class = 1)\n",
    "p3 = sum(wordSample.loc[class1].w1)/len(class1)\n",
    "#Pr(w1=1|Class = 0)\n",
    "p4 = sum(wordSample.loc[class0].w1)/len(class0)\n",
    "#Pr(w2=1|Class = 1)\n",
    "p5 = sum(wordSample.loc[class1].w2)/len(class1)\n",
    "#Pr(w2=1|Class = 0)\n",
    "p6 = sum(wordSample.loc[class0].w2)/len(class0)\n",
    "#Pr(w3=1|Class = 1)\n",
    "p7 = sum(wordSample.loc[class1].w3)/len(class1)\n",
    "#Pr(w3=1|Class = 0)\n",
    "p8 = sum(wordSample.loc[class0].w3)/len(class0)\n",
    "#Pr(w4=1|Class = 1)\n",
    "p9 = sum(wordSample.loc[class1].w4)/len(class1)\n",
    "#Pr(w4=1|Class = 0)\n",
    "p10 = sum(wordSample.loc[class0].w4)/len(class0)\n",
    "print('              ' , 'Class=1 ' , 'Class=0')\n",
    "print('   pr(Class)' , '  ' , p1 , '  ',p2)\n",
    "print('pr(w1|Class)' , '  ' , p3 , '  ',p4)\n",
    "print('pr(w2|Class)' , '  ' , p5 , '  ',p6)\n",
    "print('pr(w3|Class)' , '  ' , p7 , '  ',p8)\n",
    "print('pr(w4|Class)' , '  ' , p9 , '  ',p10)\n",
    "#compute class? | w1 = 1 & w2 = 1 assume w1, w2 are indpendent vars\n",
    "#p(class=1|w1&w2) = p(w1&w2|class=1)*p(class=1)/p(w1&w2) = p(class=1)*p(w1|class=1)*p(w2|class=1)/p(w1)*p(w2)\n",
    "#p(w1) = p(class=1)*p(w1|class=1) + p(class=0)*p(w1|class=0) \n",
    "p11 = p1*p3 + p2*p4 \n",
    "#p(w2) = p(class=1)*p(w2|class=1) + p(class=0)*p(w2|class=0)\n",
    "p12 = p1*p5 + p2*p6 \n",
    "#p(class=1|w1&w2)\n",
    "pclass1 = p1*p3*p5/(p11*p12)\n",
    "#p(class=0|w1&w2)\n",
    "pclass0 = 1-pclass1\n",
    "print('Probability for class = 0 if a document has w1 and w2 = ', pclass0)\n",
    "print('Probability for class = 1 if a document has w1 and w2 = ', pclass1)\n",
    "#So document has w1 and w2, we can classify as class = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out the naïve bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Training naive bayes\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Computing evaluation metrics\n",
      "Precision: [0.73724921 0.98322492 1.        ]\n",
      "Recall: [1.         0.94163934 0.        ]\n",
      "Accuracy: 0.9451293207638385\n"
     ]
    }
   ],
   "source": [
    "nbClassifier = train_naive_bayes(train_df.drop(columns=['earn']), train_df['earn'])\n",
    "nbPred = evaluate_classifier(nbClassifier, test_df.drop(columns=['earn']))\n",
    "compute_evaluation_metrics(test_df['earn'],nbPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out a linear classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Training linear model\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Computing evaluation metrics\n",
      "Precision: [0.73724921 0.99135926 1.        ]\n",
      "Recall: [1.         0.97803279 0.        ]\n",
      "Accuracy: 0.977519941986947\n"
     ]
    }
   ],
   "source": [
    "linearClassifier = train_linear_model(train_df.drop(columns=['earn']), train_df['earn'])\n",
    "linearPred = evaluate_classifier(linearClassifier, test_df.drop(columns=['earn']))\n",
    "compute_evaluation_metrics(test_df['earn'],linearPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1 point): Try the linear classifier with tf*idf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Evaluating classifier\n",
      "TMPY> Computing evaluation metrics\n",
      "Precision: [0.73724921 0.99213115 1.        ]\n",
      "Recall: [1.         0.99213115 0.        ]\n",
      "Accuracy: 0.9883973894126178\n"
     ]
    }
   ],
   "source": [
    "linearTfidfClassifier = pipeline.make_pipeline(feature_extraction.text.TfidfTransformer(use_idf=True), \n",
    "                                               linear_model.SGDClassifier(max_iter=100))\n",
    "linearTfidfClassifier.fit(train_df.drop(columns=['earn']), train_df['earn'])\n",
    "linearTfidfPred = evaluate_classifier(linearTfidfClassifier, test_df.drop(columns=['earn']))\n",
    "compute_evaluation_metrics(test_df['earn'],linearTfidfPred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2 points): precision-recall values for linear and decision tree based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Computing evaluation metrics\n",
      "Precision: [0.73724921 0.99135926 1.        ]\n",
      "Recall: [1.         0.97803279 0.        ]\n",
      "Accuracy: 0.977519941986947\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Computing evaluation metrics\n",
      "Precision: [0.73724921 0.98617056 1.        ]\n",
      "Recall: [1.         0.98196721 0.        ]\n",
      "Accuracy: 0.9765530577713318\n"
     ]
    }
   ],
   "source": [
    "compute_evaluation_metrics(test_df['earn'],linearPred)\n",
    "compute_evaluation_metrics(test_df['earn'], evaluate_classifier(bestTree, test_df.drop(columns=['earn'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1 point): taking the top 50 words, The performance is not affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Tokenizing documents\n",
      "TMPY> Removing stopwords\n",
      "TMPY> Stemming tokens\n",
      "TMPY> Generating dictionary\n",
      "TMPY> Vectorizing documents\n",
      "TMPY> Extracting bow features\n",
      "TMPY> Tokenizing documents\n",
      "TMPY> Removing stopwords\n",
      "TMPY> Stemming tokens\n",
      "TMPY> Vectorizing documents\n",
      "TMPY> Extracting bow features\n"
     ]
    }
   ],
   "source": [
    "tm_train = TextMiner('tmsk_trn.properties')\n",
    "tm_train.tokenize()\n",
    "tm_train.stopwords()\n",
    "tm_train.stem()\n",
    "tm_train.mkdict('earn', 295)#top50 words\n",
    "tm_train.vectorize()\n",
    "traindata_50 = extract_bow_feature(tm_train.topics, tm_train.bow, 'earn')\n",
    "vocab_50 = tm_train.vocab\n",
    "\n",
    "tm_test = TextMiner('tmsk_tst.properties')\n",
    "tm_test.tokenize()\n",
    "tm_test.stopwords()\n",
    "tm_test.stem()\n",
    "tm_test.vocab = vocab_50\n",
    "tm_test.vectorize()\n",
    "testdata_50 = extract_bow_feature(tm_test.topics, tm_test.bow, 'earn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4137, 51)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0_50 = pd.DataFrame(traindata_50[0])\n",
    "df1_50 = pd.DataFrame(traindata_50[1])\n",
    "df0_50 = pd.concat([df0_50, pd.DataFrame([0]*len(df0_50), columns=['earn'])], axis=1)\n",
    "df1_50 = pd.concat([df1_50, pd.DataFrame([1]*len(df1_50), columns=['earn'])], axis=1)\n",
    "train_df_50 = pd.concat([df0_50, df1_50]).reset_index(drop=True)\n",
    "\n",
    "df0_test_50 = pd.DataFrame(testdata_50[0])\n",
    "df1_test_50 = pd.DataFrame(testdata_50[1])\n",
    "df0_test_50 = pd.concat([df0_test_50, pd.DataFrame([0]*len(df0_test_50), columns=['earn'])], axis=1)\n",
    "df1_test_50 = pd.concat([df1_test_50, pd.DataFrame([1]*len(df1_test_50), columns=['earn'])], axis=1)\n",
    "test_df_50 = pd.concat([df0_test_50, df1_test_50]).reset_index(drop=True)\n",
    "test_df_50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Evaluating classifier\n",
      "TMPY> Computing evaluation metrics\n",
      "Precision: [0.73724921 0.98517298 1.        ]\n",
      "Recall: [1.         0.98032787 0.        ]\n",
      "Accuracy: 0.9746192893401016\n"
     ]
    }
   ],
   "source": [
    "treeClassifier_50 = DecisionTreeClassifier(max_depth=10)\n",
    "treeClassifier_50 = treeClassifier.fit(train_df_50.drop(columns=['earn']), train_df_50['earn'])\n",
    "compute_evaluation_metrics(test_df_50['earn'], evaluate_classifier(treeClassifier_50, test_df_50.drop(columns=['earn'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMPY> Training linear model\n",
      "TMPY> Evaluating classifier\n",
      "TMPY> Computing evaluation metrics\n",
      "Precision: [0.73724921 0.98098984 1.        ]\n",
      "Recall: [1.         0.98131148 0.        ]\n",
      "Accuracy: 0.9722020788010636\n"
     ]
    }
   ],
   "source": [
    "linearClassifier_50 = train_linear_model(train_df_50.drop(columns=['earn']), train_df_50['earn']) \n",
    "compute_evaluation_metrics(test_df['earn'], evaluate_classifier(linearClassifier_50, test_df_50.drop(columns=['earn'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what advantages the robust loss function has over the hinge loss function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "robust loss leads to better probability estimation at the cost of accuracy, Hinge loss some may cost of much less sensitivity regarding probabilities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
