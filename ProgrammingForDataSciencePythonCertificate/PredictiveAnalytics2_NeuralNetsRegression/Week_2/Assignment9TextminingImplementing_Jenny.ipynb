{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model\n",
    "\n",
    "from utilities import printConfusionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1 (5 points) \n",
    "\n",
    "Based on the analysis of the document, create a term-document matrix and a concept matrix. Limit the number of concepts to 20.\n",
    "\n",
    "Examine the term-document matrix \n",
    "\n",
    "Is it sparse or dense?\n",
    "\n",
    "Answer: the term-document matrix is sparse\n",
    "\n",
    "Look at the first row of the term-document matrix and determine the meaning of the non-zero elements.\n",
    "\n",
    "Answer: the first row non-zero elements means the ad that has at least one of the term 'aa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term-document matrix: 47513 terms, 4143 documents\n",
      " sparsity: 0.307%\n",
      "\n",
      "    0     1     2     3     4     5     6     7     8     9     ...   4133  \\\n",
      "aa     0     0     0     0     0     0     0     0     0     0  ...      0   \n",
      "\n",
      "    4134  4135  4136  4137  4138  4139  4140  4141  4142  \n",
      "aa     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[1 rows x 4143 columns]\n",
      "       0         1         2         3         4         5         6     \\\n",
      "0  0.912599  0.907055  0.893060  0.807469  0.857183  0.749431  0.898271   \n",
      "1 -0.199553 -0.129813 -0.061585 -0.052199 -0.026312  0.058710 -0.219140   \n",
      "2  0.246859 -0.003975 -0.160853 -0.310317 -0.226288 -0.500336  0.177987   \n",
      "3 -0.052602  0.124772  0.046488  0.247595  0.030087  0.101156  0.094909   \n",
      "4 -0.085492 -0.044585  0.014246 -0.134030 -0.166928 -0.120797 -0.048167   \n",
      "\n",
      "       7         8         9       ...         4133      4134      4135  \\\n",
      "0  0.632276  0.919159  0.903463    ...     0.854086  0.853765  0.621795   \n",
      "1  0.182430 -0.130588 -0.101721    ...     0.007438  0.008202  0.260650   \n",
      "2 -0.572734 -0.095214 -0.052848    ...    -0.223100 -0.221740 -0.409077   \n",
      "3 -0.154203  0.210593  0.097846    ...    -0.178771 -0.177860 -0.328712   \n",
      "4 -0.256949 -0.087764  0.031955    ...     0.088366  0.088150  0.070129   \n",
      "\n",
      "       4136      4137      4138      4139      4140      4141      4142  \n",
      "0  0.181650  0.182546  0.181678  0.183424  0.183262  0.184159  0.183052  \n",
      "1  0.324119  0.326133  0.323807  0.323961  0.323328  0.325338  0.323338  \n",
      "2 -0.185625 -0.190892 -0.185841 -0.182752 -0.182641 -0.187412 -0.182998  \n",
      "3 -0.150632 -0.153577 -0.150704 -0.152613 -0.151717 -0.153447 -0.152060  \n",
      "4  0.231881  0.241633  0.231817  0.234740  0.233549  0.237440  0.233065  \n",
      "\n",
      "[5 rows x 4143 columns]\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "label = []\n",
    "DATA = Path('.').resolve().parent/'data'\n",
    "farmads_df = pd.read_csv(DATA/'farm-ads.csv', header=None, names=['label', 'text'])\n",
    "farmads_df.loc[farmads_df.label == -1, 'label'] = 0\n",
    "label = list(farmads_df.label)\n",
    "corpus = list(farmads_df.text)\n",
    "preprocessor = CountVectorizer()\n",
    "preprocessedText = preprocessor.fit_transform(corpus)\n",
    "termDocumentMatrix = pd.DataFrame(data=preprocessedText.toarray().transpose(), \n",
    "                                  index=preprocessor.get_feature_names())\n",
    "print('Term-document matrix: {0[1]} terms, {0[0]} documents'.format(preprocessedText.shape))\n",
    "print(' sparsity: {:.3f}%\\n'.format(100 * preprocessedText.count_nonzero() / (preprocessedText.shape[0] * preprocessedText.shape[1])))\n",
    "tfidfTransformer = TfidfTransformer()\n",
    "tfidf = tfidfTransformer.fit_transform(preprocessedText)\n",
    "# Extract 20 concepts using LSA ()\n",
    "svd = TruncatedSVD(20)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "lsa_tfidf = lsa.fit_transform(tfidf)\n",
    "conceptMatrix = pd.DataFrame(data=lsa_tfidf.transpose())\n",
    "print(termDocumentMatrix.iloc[:1, :])\n",
    "print(conceptMatrix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2 (4 points)\n",
    "Brieﬂy explain the difference between the term-document matrix and the concept-document matrix.\n",
    "\n",
    "Answer: Both term-document matrix and concept-document matrix have rows for terms and columns for documents.\n",
    "But the term-document matrix terms is excessive for effective\n",
    "model-building, so the preprocessing steps include vocabulary reduction. The concept-document matrix limits set\n",
    "of concepts that represents most of the variation in the documents.\n",
    "we are ready to use this concept-matrix\n",
    "for classifying documents using classification methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3 (8 points)\n",
    "Using logistic regression, partition the data (60% training, 40% validation), and develop a model to classify the documents as ‘relevant’ or ‘non-relevant.’ Comment on its efficacy. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Accuracy 0.8770)\n",
      "\n",
      "         Prediction\n",
      "Reference   0   1\n",
      "        0 653 124\n",
      "        1  80 801\n"
     ]
    }
   ],
   "source": [
    "# split dataset into 60% training and 40% test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(lsa_tfidf, label, test_size=0.4, random_state=12345)\n",
    "\n",
    "# run logistic regression model on training\n",
    "logit_reg = linear_model.LogisticRegression()\n",
    "logit_reg.fit(Xtrain, ytrain)\n",
    "\n",
    "# print confusion matrix and accuracty\n",
    "printConfusionMatrix(ytest, logit_reg.predict(Xtest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4 (3 points)\n",
    "Why use the concept-document matrix, and not the term-document matrix, to provide the predictor variables?\n",
    "\n",
    "Answer: The concept-document matrix limits set of concepts that represents most of the variation in the documents. But the term-document matrix has no vocabulary reduction etc, it is super sparse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
